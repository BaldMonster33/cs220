{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL PROJECT: CS220 Spring 2020\n",
    "## This is an individual exam. Do not work with a partner! Only change \"submitter\" netid information. Good luck.\n",
    "- For majority of the questions you need to replace \"# Write your code here\" comment with your own code.\n",
    "- There are 27 questions, each of which will be weighted 0.55 points.\n",
    "- Unlike projects, you will receive partial credit for a question as long as your code runs and produces an output for each question.\n",
    "- Unlike projects, you do not have access to \"test.py\". Instead, you can use \"type_test.py\". This file does not check if your answers are correct, but it checks if your answers are in the correct format.\n",
    "- \"test.py\" will run \"lint.py\" and deduct points for linting errors. You will lose 0.1 points for each linting error. You will only lose points for warnings, not convention messages (just like in P10). type_test.py does not run the linter, so check with lint.py before turning your work in. For more information about the linter as well as how to run the full linter to see all of the automatically generated advice and feedback, please check out the linting README: https://github.com/msyamkumar/cs220-projects/tree/master/linter.\n",
    "- General hint: if you see a lot of hints / write up before a question, it is likely to be difficult question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project: final\n",
    "# submitter: lqin33\n",
    "# partner: none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended to use this cell to add import statements\n",
    "import os, csv\n",
    "import requests\n",
    "import json\n",
    "import sqlite3 as sql\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>em { color: red; }</style> <style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just run this cell (it's just to make certain text red, but you don't need to understand it).\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<style>em { color: red; }</style> <style>.container { width:100% !important; }</style>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions q1 to q10 address topics covered by projects P2 to P4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Is *map_dummy* an *iterable* data structure? \n",
    "- Complete the below code to demonstrate this. \n",
    "- Your cell should only output either *True* or *False*. \n",
    "- You *should not hardcode* the answer to this question.\n",
    "- Hint: recall how to do nothing in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1: Is map_dummy an iterable data structure? True or False\n",
    "# noinspection PyBroadException\n",
    "map_dummy = map(str, [4,2,1.0])\n",
    "try:\n",
    "    # Write your code here\n",
    "    iter(map_dummy)\n",
    "    result = True\n",
    "except TypeError:\n",
    "    result = False\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Can we use a *list* as a *key in a dictionary*?\n",
    "- Complete the below code to demonstrate this. \n",
    "- Your cell should only output either *True* or *False*. \n",
    "- You *should not hardcode* the answer to this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2: Can we use a list as a key in a dictionary? True or False\n",
    "\n",
    "try:\n",
    "    list_1 = []\n",
    "    dict_1 = {}\n",
    "    dict_1[list_1] = 'try'\n",
    "    # Write your code here\n",
    "    result = True\n",
    "except TypeError:\n",
    "    result = False\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Complete *falsify* function such that if *bool_list* contains one or more occurences of \"False\", returned value is False. Otherwise returned value is True. \n",
    "- You may add multiple lines of code inside the Falsify function.\n",
    "- Your code must work with a list of any length!\n",
    "- Your cell should only output a list containing two boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3: Complete *Falsify* function such that if *bool_list* contains one or more occurences \n",
    "#of \"False\", returned value is False. Otherwise returned value is True. \n",
    "\n",
    "def falsify(bool_list):\n",
    "    return \"False\" in bool_list\n",
    "    # Write your code here\n",
    "\n",
    "# Test 1\n",
    "test_list = [\"True\", \"True\", \"False\", \"True\"]\n",
    "test_1 = falsify(test_list)\n",
    "\n",
    "# Test 2\n",
    "test_list = [\"True\", \"True\", \"Apple\", \"True\"]\n",
    "test_2 = falsify(test_list)\n",
    "[test_1, test_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the following *data structure* to answer the next two questions *q4* and *q5*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Student = namedtuple(\"Student\", [\"name\", \"id\"])\n",
    "data_struct = {\n",
    "    \"cs\": [Student(\"John\", \"netID123\"), Student(\"Martha\", \"netID123\")],\n",
    "    \"econ\": [Student(\"John\", \"netID5678_econ\"), Student(\"Peter\", \"netID5679_econ\")]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: What is the *ID* for *John from Economics*?\n",
    "- Your cell should only output the ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q4: What is the ID for John from Economics?\n",
    "data_struct['econ'][0].name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: List the *names* of all students in *CS*.\n",
    "- Your answer should be in the form of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John', 'Martha']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q5: List the names of all students in CS.\n",
    "list_1 = []\n",
    "for i in range(len(data_struct)):\n",
    "    list_1.append(data_struct['cs'][i].name)\n",
    "\n",
    "list_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6:  Use *list slicing* to right rotate list [1,2,3,4] by three places.\n",
    "- Hint: When you rotate a list like [1,2,3,4] right by one place, you get [4,1,2,3].\n",
    "- Your answer should be in the form of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q6: Use list slicing to right rotate list [1,2,3,4] by three places\n",
    "\n",
    "original_list = [1,2,3,4]\n",
    "n = 3\n",
    "new_list = (original_list[-n:] + original_list[:-n])\n",
    "new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing cereal.csv dataset (q7 to q14)\n",
    "### Write a function that *reads* in the *cereal.csv* file and stores the data as a variable. \n",
    "- Make sure to write a generic function that takes csv file as input and returns the data (for reusability)\n",
    "- Download \"cereal.csv\" to the same local directory.\n",
    "- *Do not use any additional path* to your data file - this will *mess up grading*!\n",
    "- We will be using this variable through the next set of questions (q7 to q15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read csv file\n",
    "def read_csv(path):\n",
    "    file = open(path, encoding = 'utf-8')\n",
    "    file_reader = csv.reader(file)\n",
    "    data = list(file_reader)\n",
    "    file.close()\n",
    "    return data\n",
    "\n",
    "data_csv = read_csv('cereal.csv')\n",
    "data_header = data_csv[0]\n",
    "data = data_csv[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: What is the *carbohydrate content* in the cereal named \"*Cheerios*\"? \n",
    "- Recall that you shouldn't hardcode the index for looking up a particular column's value.\n",
    "- Follow the index lookup for all further questions.\n",
    "- You should make sure to look up the index of the column using the csv header first.\n",
    "- Your cell should output a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q7: What is the carbohydrate content in the cereal named \"Cheerios\"?\n",
    "index_of_carbo = data_header.index('carbo')\n",
    "index_of_name = data_header.index('name')\n",
    "def find_cereal_carbo(name):\n",
    "    for i in data:\n",
    "        if i[index_of_name] == name:\n",
    "            return float(i[index_of_carbo])\n",
    "find_cereal_carbo('Cheerios')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: What is the *cereal* with the *highest rating*?\n",
    "- Report your answer as a dictionary.\n",
    "- *key* as the *cereal name* and *value* as the *numerical rating*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'All-Bran with Extra Fiber': 93.704912}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q8: What is the cereal with the highest rating?\n",
    "index_of_rating = data_header.index('rating')\n",
    "def append_all(header):\n",
    "    list_1 = []\n",
    "    index_of_header = data_header.index(header)\n",
    "    for i in data:\n",
    "        try:\n",
    "            list_1.append(float(i[index_of_header]))\n",
    "        except ValueError:\n",
    "            list_1.append(i[index_of_header])\n",
    "\n",
    "    return list_1\n",
    "\n",
    "def append_data_all(header, data, data_header = data_header):\n",
    "    list_1 = []\n",
    "    index_of_header = data_header.index(header)\n",
    "    for i in data:\n",
    "        try:\n",
    "            list_1.append(float(i[index_of_header]))\n",
    "        except ValueError:\n",
    "            list_1.append(i[index_of_header])\n",
    "    return list_1\n",
    "            \n",
    "highest_rating = max(append_all('rating'))\n",
    "\n",
    "def find_highest_rating_cereal():\n",
    "    keys = []\n",
    "    values = []\n",
    "    dict_1 = {}\n",
    "    for i in data:\n",
    "        if float(i[index_of_rating]) == highest_rating:\n",
    "            keys.append(i[index_of_name])\n",
    "            values.append(i[index_of_rating])\n",
    "    dict_1[keys[0]] = float(values[0])\n",
    "    return dict_1\n",
    "\n",
    "find_highest_rating_cereal() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: Write *a function* that computes the *mininum, maximum, and average* for a given numerical column of the cereal data and returns these data as a dictionary. Report the basic statistics for the *fat* column.\n",
    "- Example output: \n",
    "```result = {\"min\": 0.1, \"max\":5.2, \"mean\": 2.2}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 0.0, 'max': 5.0, 'mean': 1.0129870129870129}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q9: Write a function that computes the mininum, maximum, and average for a given \n",
    "# numerical column of the cereal data and returns these data as a dictionary.\n",
    "# Report the basic statistics for the fat column.\n",
    "\n",
    "def find_stats(col_name):\n",
    "    stats = append_all(col_name)\n",
    "    result = {}\n",
    "    result['min'] = min(stats)\n",
    "    result['max'] = max(stats)\n",
    "    result['mean'] = sum(stats) / len(stats)\n",
    "    return result\n",
    "    #write your code here\n",
    "\n",
    "result = find_stats('fat')\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10: Find the *difference* between the *average sugar content* of all cereals that are rated below 30 and the ones above 50.\n",
    "- Your cell should output a float value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.783882783882785"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q10: Find the difference between the average sugar content of all cereals \n",
    "# that are rated below 30 \n",
    "# and the ones above 50\n",
    "index_of_sugar = data_header.index('sugars')\n",
    "\n",
    "def find_selected_avg(num, types):\n",
    "    list_1 = []\n",
    "    for i in data:\n",
    "        if types == 'above':\n",
    "            if float(i[index_of_rating]) > num:\n",
    "                list_1.append(float(i[index_of_sugar]))\n",
    "        elif types == 'below':\n",
    "            if float(i[index_of_rating]) < num:\n",
    "                list_1.append(float(i[index_of_sugar]))\n",
    "        else:\n",
    "            print('please choose types from above and below')\n",
    "                \n",
    "    return sum(list_1)/len(list_1)\n",
    "\n",
    "avg_sugar_below_30 = find_selected_avg(30, 'below')\n",
    "avg_sugar_above_50 = find_selected_avg(50, 'above')\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "avg_sugar_below_30 - avg_sugar_above_50 # don't change this line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions q11 to q14 address topics covered by projects P5 and P6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11: How many products are in the cereal dataset?\n",
    "- Your cell should output an int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q11: How many products are in the cereal dataset?\n",
    "\n",
    "def find_products():\n",
    "    list_1 = []\n",
    "    for i in data:\n",
    "        if i[index_of_name] not in list_1:\n",
    "            list_1.append(i[index_of_name])\n",
    "    return len(list_1)\n",
    "\n",
    "find_products()         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12: What is the *product name* in the cereal data that has the *third highest rating*?\n",
    "- Hints:\n",
    "   - You need need to re-order your cereal data by ratings.\n",
    "   - Recall that the typical function you use for re-ordering has a parameter called *key*, which enables you to write a getter function for lookup of specific column value.\n",
    "- Your cell should output str value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shredded Wheat spoon size'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q12: What is the product name in the cereal data that has the third highest rating?\n",
    "data_by_rating = sorted(data,key=(lambda x:x[index_of_rating]), reverse = True)\n",
    "data_by_rating[2][index_of_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13: What are *product names* that meet the following criteria:\n",
    "1. *2 ≤ fat ≤ 5*\n",
    "2. *rating ≥ 30*\n",
    "3. *100 ≤ sodium ≤ 200*\n",
    "- Your answer should be a list with the items names (str) sorted in lexicographical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Almond Delight',\n",
       " 'Clusters',\n",
       " \"Cracklin' Oat Bran\",\n",
       " 'Fruit & Fibre Dates; Walnuts; and Oats',\n",
       " 'Life',\n",
       " 'Muesli Raisins; Peaches; & Pecans',\n",
       " 'Mueslix Crispy Blend',\n",
       " 'Oatmeal Raisin Crisp',\n",
       " 'Raisin Nut Bran']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q13: What are product names that meet the following criteria:\n",
    "   # 2 ≤ fat ≤ 5\n",
    "   # rating ≥ 30\n",
    "   # 100 ≤ sodium ≤ 200\n",
    "\n",
    "index_of_fat = data_header.index('fat')\n",
    "index_of_sodium = data_header.index('sodium')\n",
    "\n",
    "def criteria(x):\n",
    "    #if x[index_of_fat] in [2,5] and x[index_of_rating] >= 30 and x[sodium] in [100, 200]:\n",
    "    return 2 <= float(x[index_of_fat]) <= 5 and float(x[index_of_rating]) >= 30 and 100 <= float(x[index_of_sodium]) <= 200\n",
    "    \n",
    "products = list(filter(criteria, data))\n",
    "def find_names(products):\n",
    "    list_1 = []\n",
    "    for product in products:\n",
    "        list_1.append(product[index_of_name])\n",
    "    return sorted(list_1)\n",
    "        \n",
    "find_names(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14: Write a function *find_word(keyword)* that returns a list of product names that have *keyword* in the product name.\n",
    "- Keyword match:\n",
    "  - should be *case insensitive*\n",
    "  - should be *complete match (not a substring match)*, with the exception of \"'\" and \"-\" (see below example for details)\n",
    "  - apply split(...) method for handling / eliminating \"-\" and \"'\" from the comparsion\n",
    "  - Hint: this question is all about extracting individual words from the product name and iterating over those words. It is likely that you will need nested loops.\n",
    "- *Order the list* with the highest rated cereal first and the lowest rated cereal last:\n",
    "  - Hint: you already did something similar for #q12. Reuse the same getter function here.\n",
    "- The match result should not consider substring match:\n",
    "  - Let's say keyword is \"Apple\", and product names are [\"Apple pie\", \"Apple's seed\", \"Applewatch\", \"apple-pay\", \"apples\"].\n",
    "  - In this example only \"Apple pie\", \"Apple's seed\", and \"apple-pay\" matches with keyword. \n",
    "  - \"Applewatch\" and \"apples\" are NOT qualified since there are additional letters concatenated to the keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Shredded Wheat'n'Bran\",\n",
       " 'Shredded Wheat spoon size',\n",
       " 'Shredded Wheat',\n",
       " 'Cream of Wheat (Quick)',\n",
       " 'Puffed Wheat',\n",
       " 'Nutri-grain Wheat',\n",
       " 'Frosted Mini-Wheat',\n",
       " 'Wheat Chex',\n",
       " 'Crispy Wheat & Raisins']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q14: Write a function find_word(keyword) that returns a list of product names that have \n",
    "# keyword in the product name.\n",
    "\n",
    "def sort_by_rating(x):\n",
    "    names = append_data_all('name', data_by_rating)\n",
    "    for i in range(len(names)):\n",
    "        if x == names[i]:\n",
    "            return i\n",
    "\n",
    "def find_word(keyword):\n",
    "    name_list = append_all('name')\n",
    "    raw_list = []\n",
    "    for i in range(len(name_list)):\n",
    "        word = name_list[i].lower().find((keyword.lower()))\n",
    "        if word != -1:\n",
    "            try:\n",
    "                d = name_list[i][int(word) + len(keyword)]\n",
    "                if d in (' ', \"'\", '-'):\n",
    "                    raw_list.append(name_list[i])\n",
    "            except IndexError:\n",
    "                try:\n",
    "                    d = name_list[i][int(word) + len(keyword) - 1]\n",
    "                    if d == keyword[-1]:\n",
    "                        raw_list.append(name_list[i])\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "    return sorted(raw_list, key = (lambda x:sort_by_rating(x)))\n",
    "\n",
    "find_word(\"Wheat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing player_data.csv dataset (q15 to q18)\n",
    "## Questions q15 to q18 address topics covered by project P7.\n",
    "\n",
    "### Read *player_data.csv* using the csv reading function that you already wrote.\n",
    "- Download the NBA players dataset \"player_data.csv\" to the same local directory.\n",
    "- *Do not use any additional path* to your data file - this will *mess up grading*!\n",
    "- We will be using this variable through the next set of questions (q15 to q18).\n",
    "- For all the questions you should *skip all players who have some entries in the column are missing* (i.e., some entry is just the empty string).\n",
    "- Consider writing a *cell* function to convert appropriate columns into their correct data type!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15 : How many *complete players* in the dataset? \n",
    "- Reminder: skip all players who have some entries in the column are missing.\n",
    "- Hint: answer should be lower than 4550!\n",
    "- Your cell should output an int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4213"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q15: How many complete players in the dataset? skip all players who have some entries \n",
    "# in the column are missing. i.e. one or more of the entries is the empty string.\n",
    "\n",
    "player_csv = read_csv('player_data.csv')\n",
    "player_header = player_csv[0]\n",
    "player_data = player_csv[1:]\n",
    "\n",
    "def find_non_empty_players(x):\n",
    "    idx = 0\n",
    "    for i in range(len(player_header)):\n",
    "        if len(x[i]) != 0 and x[i] != None:\n",
    "            idx += 1\n",
    "    if idx == len(player_header):\n",
    "        return x\n",
    "\n",
    "def cell(row_idx, col_name):\n",
    "    col_idx = player_header.index(col_name)\n",
    "    val = new_data[row_idx][col_idx]\n",
    "    if val == \"\":\n",
    "        return None\n",
    "    if col_name in ('year_start', 'year_end', 'weight'):\n",
    "        return int(val)\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "new_data = list(filter(find_non_empty_players, player_data))\n",
    "len(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16: What are the *stats* for the player whose name is \"*Michael Jordan*\"?\n",
    "- Answer in the form of a dict. \n",
    "- See the example below:\n",
    "```example = {'name': 'Alaa Abdelnaby',\n",
    " 'year_start': 1991,\n",
    " 'year_end': 1995,\n",
    " 'position': 'F-C',\n",
    " 'height': '6-10',\n",
    " 'weight': 240,\n",
    " 'birth_date': 'June 24, 1968',\n",
    " 'college': 'Duke University'}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def list_to_dict():\n",
    "#     player_dict = []\n",
    "#     for player in new_data:\n",
    "#         dict_1 = {}\n",
    "#         for i in range(len(player_header)):\n",
    "#             dict_1[player_header[i]] = player[i]\n",
    "#         player_dict.append(dict_1)\n",
    "#     return player_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Michael Jordan',\n",
       " 'year_start': 1985,\n",
       " 'year_end': 2003,\n",
       " 'position': 'G-F',\n",
       " 'height': '6-6',\n",
       " 'weight': 195,\n",
       " 'birth_date': 'February 17, 1963',\n",
       " 'college': 'University of North Carolina'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q16: What are the stats for the player whose name is \"Michael Jordan\"?\n",
    "def list_to_dict():\n",
    "    player_dict = []\n",
    "    for idx in range(len(new_data)):\n",
    "        dict_1 = {}\n",
    "        for i in range(len(player_header)):\n",
    "            dict_1[player_header[i]] = cell(idx, player_header[i])\n",
    "        player_dict.append(dict_1)\n",
    "    return player_dict\n",
    "\n",
    "player_dict = list_to_dict()\n",
    "\n",
    "def find_values(col_name, name):\n",
    "    list_1 = []\n",
    "    for player in player_dict:\n",
    "        if player[col_name] == name:\n",
    "            list_1.append(player)\n",
    "    if len(list_1) == 1:\n",
    "        return list_1[0]\n",
    "    else:\n",
    "        return list_1\n",
    "        \n",
    "find_values('name', \"Michael Jordan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 17: What are the *stats* for the *players* whose college is *\"University of Wisconsin\"*?\n",
    "- Your output should be a list of dictionaries. \n",
    "- Each dictionary should be similar to the example in the previous question.\n",
    "- Hint: consider writing a bucketize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Cory Blackwell',\n",
       "  'year_start': 1985,\n",
       "  'year_end': 1985,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 210,\n",
       "  'birth_date': 'March 27, 1963',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Paul Cloyd',\n",
       "  'year_start': 1950,\n",
       "  'year_end': 1950,\n",
       "  'position': 'G-F',\n",
       "  'height': '6-2',\n",
       "  'weight': 180,\n",
       "  'birth_date': 'June 13, 1920',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Bobby Cook',\n",
       "  'year_start': 1950,\n",
       "  'year_end': 1950,\n",
       "  'position': 'G-F',\n",
       "  'height': '5-10',\n",
       "  'weight': 155,\n",
       "  'birth_date': 'April 1, 1923',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Sam Dekker',\n",
       "  'year_start': 2016,\n",
       "  'year_end': 2018,\n",
       "  'position': 'F',\n",
       "  'height': '6-9',\n",
       "  'weight': 230,\n",
       "  'birth_date': 'May 6, 1994',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Duje Dukan',\n",
       "  'year_start': 2016,\n",
       "  'year_end': 2016,\n",
       "  'position': 'F',\n",
       "  'height': '6-9',\n",
       "  'weight': 220,\n",
       "  'birth_date': 'December 4, 1991',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Gene Englund',\n",
       "  'year_start': 1950,\n",
       "  'year_end': 1950,\n",
       "  'position': 'F-C',\n",
       "  'height': '6-5',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'October 21, 1917',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Michael Finley',\n",
       "  'year_start': 1996,\n",
       "  'year_end': 2010,\n",
       "  'position': 'G-F',\n",
       "  'height': '6-7',\n",
       "  'weight': 215,\n",
       "  'birth_date': 'March 6, 1973',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Paul Grant',\n",
       "  'year_start': 1999,\n",
       "  'year_end': 2004,\n",
       "  'position': 'C',\n",
       "  'height': '7-0',\n",
       "  'weight': 245,\n",
       "  'birth_date': 'January 6, 1974',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Claude Gregory',\n",
       "  'year_start': 1986,\n",
       "  'year_end': 1988,\n",
       "  'position': 'F',\n",
       "  'height': '6-8',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'December 26, 1958',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Devin Harris',\n",
       "  'year_start': 2005,\n",
       "  'year_end': 2018,\n",
       "  'position': 'G',\n",
       "  'height': '6-3',\n",
       "  'weight': 192,\n",
       "  'birth_date': 'February 27, 1983',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Al Henry',\n",
       "  'year_start': 1971,\n",
       "  'year_end': 1972,\n",
       "  'position': 'C',\n",
       "  'height': '6-9',\n",
       "  'weight': 190,\n",
       "  'birth_date': 'February 9, 1949',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Doug Holcomb',\n",
       "  'year_start': 1949,\n",
       "  'year_end': 1949,\n",
       "  'position': 'F',\n",
       "  'height': '6-4',\n",
       "  'weight': 200,\n",
       "  'birth_date': 'February 9, 1925',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Kim Hughes',\n",
       "  'year_start': 1976,\n",
       "  'year_end': 1981,\n",
       "  'position': 'C',\n",
       "  'height': '6-11',\n",
       "  'weight': 220,\n",
       "  'birth_date': 'June 4, 1952',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Frank Kaminsky',\n",
       "  'year_start': 2016,\n",
       "  'year_end': 2018,\n",
       "  'position': 'F-C',\n",
       "  'height': '7-0',\n",
       "  'weight': 242,\n",
       "  'birth_date': 'April 4, 1993',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Marcus Landry',\n",
       "  'year_start': 2010,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-7',\n",
       "  'weight': 230,\n",
       "  'birth_date': 'November 1, 1985',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Walt Lautenbach',\n",
       "  'year_start': 1950,\n",
       "  'year_end': 1950,\n",
       "  'position': 'G-F',\n",
       "  'height': '6-2',\n",
       "  'weight': 185,\n",
       "  'birth_date': 'November 17, 1922',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Jon Leuer',\n",
       "  'year_start': 2012,\n",
       "  'year_end': 2018,\n",
       "  'position': 'F',\n",
       "  'height': '6-10',\n",
       "  'weight': 228,\n",
       "  'birth_date': 'May 14, 1989',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Wes Matthews',\n",
       "  'year_start': 1981,\n",
       "  'year_end': 1990,\n",
       "  'position': 'G',\n",
       "  'height': '6-1',\n",
       "  'weight': 170,\n",
       "  'birth_date': 'August 24, 1959',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Kirk Penney',\n",
       "  'year_start': 2004,\n",
       "  'year_end': 2005,\n",
       "  'position': 'G',\n",
       "  'height': '6-5',\n",
       "  'weight': 220,\n",
       "  'birth_date': 'November 23, 1980',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Don Rehfeldt',\n",
       "  'year_start': 1951,\n",
       "  'year_end': 1952,\n",
       "  'position': 'F',\n",
       "  'height': '6-7',\n",
       "  'weight': 210,\n",
       "  'birth_date': 'January 7, 1927',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Scott Roth',\n",
       "  'year_start': 1988,\n",
       "  'year_end': 1990,\n",
       "  'position': 'F',\n",
       "  'height': '6-8',\n",
       "  'weight': 212,\n",
       "  'birth_date': 'June 3, 1963',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Dick Schulz',\n",
       "  'year_start': 1947,\n",
       "  'year_end': 1950,\n",
       "  'position': 'F-G',\n",
       "  'height': '6-2',\n",
       "  'weight': 192,\n",
       "  'birth_date': 'January 3, 1917',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Glen Selbo',\n",
       "  'year_start': 1950,\n",
       "  'year_end': 1950,\n",
       "  'position': 'G-F',\n",
       "  'height': '6-3',\n",
       "  'weight': 196,\n",
       "  'birth_date': 'March 29, 1926',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Greg Stiemsma',\n",
       "  'year_start': 2012,\n",
       "  'year_end': 2015,\n",
       "  'position': 'C',\n",
       "  'height': '6-11',\n",
       "  'weight': 260,\n",
       "  'birth_date': 'September 26, 1985',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q17: What are the stats for the players whose college is \"University of Wisconsin\"\n",
    "find_values('college', 'University of Wisconsin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 18: What is the average *weight* for each *position*?\n",
    "- Answer with a dictionary, mapping the key \"position\" to the value \"average weight\" (float type).\n",
    "- Average is the same as mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'G': 186.82811459027315,\n",
       " 'F-C': 222.91944444444445,\n",
       " 'C-F': 228.25615763546799,\n",
       " 'C': 242.2192118226601,\n",
       " 'F-G': 202.60487804878048,\n",
       " 'G-F': 197.01785714285714,\n",
       " 'F': 217.98585690515807}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q18: What is the average \"weight\" for each \"position\"?\n",
    "\n",
    "def find_numbers_of_position():\n",
    "    return list(set(append_data_all('position', new_data, data_header = player_header)))\n",
    "\n",
    "player_positions = find_numbers_of_position()\n",
    "\n",
    "def find_average(positions, col_name, avg_term):\n",
    "    dict_1 = {}\n",
    "    for position in positions:\n",
    "        weight = 0\n",
    "        idx = 0\n",
    "        for data in player_dict:\n",
    "            if data[col_name] == position:\n",
    "                weight += data[avg_term]\n",
    "                idx += 1\n",
    "        dict_1[position] = weight/idx\n",
    "    return dict_1\n",
    "\n",
    "find_average(player_positions, 'position', 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing netflix_titles.html (to be converted to Python data structure) dataset (q19 to q21)\n",
    "## Question q19 addresses topics covered by project P10.\n",
    "\n",
    "### Question 19: Download and parse netflix_titles.html and write the data into a list-of-lists or list-of-dictionaries\n",
    "- This dataset *should not be manually* downloaded!\n",
    "- To download this html file, complete the below download function (this part is from project P10).\n",
    "- Next step is to parse the html data to store it in a data structure, either list-of-lists or list-of-dictionaries.\n",
    "- You need to use BeautifulSoup functions find() and find_all().\n",
    "- Recall that *table* tag contains *tr* tags for rows.\n",
    "- Recall that *tr* tags contain *td* tags for the actual data.\n",
    "- Recall that you can extract *text* from any tag.\n",
    "- The headers for this dataset are the following:\n",
    "```\n",
    "['show_id',\n",
    " 'type',\n",
    " 'title',\n",
    " 'director',\n",
    " 'cast',\n",
    " 'country',\n",
    " 'date_added',\n",
    " 'release_year',\n",
    " 'rating',\n",
    " 'duration',\n",
    " 'listed_in',\n",
    " 'description']\n",
    "```\n",
    "- This cell should output the following after successful parsing:\n",
    "```\n",
    "['Norm of the North: King Sized Adventure',\n",
    " 'Jandino: Whatever it Takes',\n",
    " 'Transformers Prime']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Norm of the North: King Sized Adventure',\n",
       " 'Jandino: Whatever it Takes',\n",
       " 'Transformers Prime']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q19: Download and parse netflix_titles.html.\n",
    "#Follow the detailed steps given in the below function outline.\n",
    "\n",
    "# Complete the missing parts in the below download function\n",
    "\n",
    "def download(filename, url):\n",
    "    # We do not download again if the file already exists\n",
    "    if os.path.exists(filename):\n",
    "        return (str(filename) + \" already exists!\")\n",
    "    else:\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        data = r.text\n",
    "        f = open(filename, \"w\", encoding=\"utf-8\")\n",
    "        f.write(data)\n",
    "        f.close()\n",
    "    return (str(filename) + \" created!\")\n",
    "\n",
    "#Do not change this line\n",
    "download(\"netflix_titles.html\", \\\n",
    "         \"https://raw.githubusercontent.com/msyamkumar/cs220-projects/master/spring20/final/netflix_titles.html\")\n",
    "\n",
    "def parse_html_contents(html_file):\n",
    "    #To store the parsed data\n",
    "    netflix_data = []\n",
    "    \n",
    "    # Open and read the html file\n",
    "    # Write your code here\n",
    "    \n",
    "    html_doc = open(html_file,encoding='utf-8')\n",
    "    html_doc = html_doc.read()\n",
    "    # Create a BeautifulSoup type\n",
    "    # Write your code here\n",
    "    \n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "    # Find the dataset table\n",
    "    # Write your code here\n",
    "    \n",
    "    table = soup.find(\"table\")\n",
    "    \n",
    "    # Find the rows in the table. Hint: separate your header versus data processing here.\n",
    "    # Write your code here\n",
    "    \n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    # Find data for header row: you can generate a list of str here (see above output for reference)\n",
    "    # Write your code here\n",
    "    \n",
    "    header = rows[0]\n",
    "    items = header.find_all('td')\n",
    "    header_list = [item.get_text() for item in items]\n",
    "    # Find data for the remaining rows:\n",
    "    # To store this dataset, choose between list-of-lists or list-of-dictionaries\n",
    "    # Write your code here\n",
    "    \n",
    "    for i in rows[1:]:\n",
    "        data_list = i.find_all('td')\n",
    "        dict_1 = {}\n",
    "        for idx, item in enumerate(data_list):\n",
    "            dict_1[header_list[idx]] = item.get_text()\n",
    "        netflix_data.append(dict_1)\n",
    "    \n",
    "    return netflix_data \n",
    "    # If you want to return header data also, change the above line to something like this:\n",
    "    # return netflix_header, netflix_data\n",
    "    \n",
    "netflix_data = parse_html_contents(\"netflix_titles.html\") #Do not change these lines\n",
    "top_3_titles = []\n",
    "for row in netflix_data[:3]:\n",
    "    # Retrieve top 3 titles from your data structure (see above output for reference)\n",
    "    top_3_titles.append(row['title'])\n",
    "top_3_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions q20 to q21 address topics covered by project P8.\n",
    "### Question 20: List the *first 10* TV shows' *titles* in the dataset.\n",
    "- There are different types of Netflix videos in this dataset, such as TV shows and movies. \n",
    "- This question asks you to list *only* first 10 *TV shows*.\n",
    "- Your cell should output a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transformers Prime',\n",
       " 'Transformers: Robots in Disguise',\n",
       " 'Apaches',\n",
       " 'Fire Chasers',\n",
       " 'Castle of Stars',\n",
       " 'First and Last',\n",
       " \"Archibald's Next Big Thing\",\n",
       " 'The Spy',\n",
       " 'No Tomorrow',\n",
       " 'Frequency']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q20: List the first 10 TV shows' titles in the dataset.\n",
    "def list_TV_shows():\n",
    "    list_1 = []\n",
    "    for i in netflix_data:\n",
    "        if i['type'] == 'TV Show':\n",
    "            list_1.append(i['title'])\n",
    "    return list_1\n",
    "    \n",
    "list_TV_shows()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 21: How many *movies* released *after 2015 (inclusive)* are in this dataset?\n",
    "- This question asks you to consider *only movies*.\n",
    "- Your cell should output an int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q21: How many movies released after 2015 (inclusive) are in this dataset?\n",
    "\n",
    "def find_movies(x):\n",
    "    if int(x['release_year']) <= 2015 and x['type'] == 'Movie':\n",
    "        return x\n",
    "new_movies = list(filter(find_movies, netflix_data))\n",
    "\n",
    "\n",
    "len(new_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the movies data in the data folder (q22, q23).\n",
    "## Questions q22, q23 address topics covered by project P9.\n",
    "\n",
    "- The data folder consists of two things\n",
    "  1. movies.csv, which consists of the movie_id, title, and genres corresponding to the movie. \n",
    "  2. The users directory inside the data folder consists of the ratings given by 10 users in files named from 1.json to 10.json.\n",
    "     - The first attribute in the file refers to the movie_id, and second attribute refers to the rating given by that user to that movie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 22: What is the *average rating* for the movie with id *34*?\n",
    "- Combine all the json files in the users directory inside the data directory and calculate the average rating for the movie ids present in these files.\n",
    "- Remember a particular movie_id can be part of multiple files!\n",
    "- You can read the json files one by one and add the entries to a dictionary:\n",
    "  - with the key as the movie_id (in integer format) and as the value you can maintan a list of ratings \n",
    "  - each rating value stored as a float\n",
    "- You can now iterate over the created dictionary and calculate the average rating corresponding to each movie_id\n",
    "- Your cell should output a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.333333333333333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q22: What is the average rating for the movie with id 34?\n",
    "\n",
    "\n",
    "def read_files(path_name):\n",
    "    if path_name.endswith('.json'):\n",
    "        f = open(path_name, encoding=\"utf-8\")\n",
    "        reader = json.load(f)\n",
    "    elif path_name.endswith('.csv'):\n",
    "        f = open(path_name, encoding=\"utf-8\")\n",
    "        reader = list(csv.DictReader(f))\n",
    "        reader = json.loads(json.dumps(reader))     \n",
    "    else:\n",
    "        reader = \"Input Wrong Type of File\"\n",
    "    return(reader)\n",
    "\n",
    "def find_all_json_files():\n",
    "    list_1 = []\n",
    "    for obj in os.listdir(os.path.join('data', 'users')):\n",
    "        list_1.append(os.path.join('data','users', obj))\n",
    "    return list_1\n",
    "\n",
    "all_json_files = find_all_json_files()\n",
    "\n",
    "def find_rating(json_file, num_ID):\n",
    "    json_file = read_files(json_file)\n",
    "    list_1 = []\n",
    "    rating = 0.0\n",
    "    idx = 0\n",
    "    try:\n",
    "        rating += float(json_file[num_ID])\n",
    "        idx += 1\n",
    "        list_1.append(rating)\n",
    "        list_1.append(idx)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return list_1\n",
    "\n",
    "def find_avg_rating(json_files, num_ID):\n",
    "    rating = 0.0\n",
    "    idx = 0\n",
    "    for file in json_files:\n",
    "        try:\n",
    "            rating += find_rating(file, num_ID)[0]\n",
    "            idx += find_rating(file, num_ID)[1]\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return float(rating / idx)\n",
    "\n",
    "find_avg_rating(all_json_files, '34')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 23: What is the *minimum rating* for the movie *Batman (1989)*?\n",
    "- You can find the names of the movies in the CSV file.\n",
    "- Make sure to use *os.path.join* while opening the file and do not hardcode the slashes!\n",
    "- You have to combine the data from the CSV file with the data from the JSON files.\n",
    "- Your cell should output a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q23: What is the *minimum rating* for the movie *Batman (1989)*?\n",
    "read_files('data/movies.csv')\n",
    "\n",
    "def find_ID(name):\n",
    "    file = read_files('data/movies.csv')\n",
    "    for i in file:\n",
    "        if i['title'] == name:\n",
    "            return i['movieId']\n",
    "        \n",
    "batman_id = find_ID('Batman (1989)')\n",
    "\n",
    "def find_min_rating():\n",
    "    min_value = 10\n",
    "    for file in all_json_files:\n",
    "        try:\n",
    "            min_value = min(find_rating(file, batman_id)[0], min_value)\n",
    "        except KeyError :\n",
    "            continue\n",
    "    return min_value\n",
    "\n",
    "find_min_rating()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing countries.db - same dataset as P10 (q24 to q27).\n",
    "## Questions q24 to q27 address topics covered by project P10.\n",
    "- Create a sqlite connection to this database.\n",
    "- You can use either SQL querries or Pandas statements to answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 24: What is the *capital* of *Namibia*?\n",
    "- Answer as a python string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Windhoek'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q24: What is the capital of Namibia?\n",
    "\n",
    "conn = sql.connect('countries.db')\n",
    "c = conn.cursor()\n",
    "c.execute('''\n",
    "SELECT capital FROM capitals\n",
    "WHERE country = 'Namibia'\n",
    "''')\n",
    "c.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 25: What is the *population* of *each continent*?\n",
    "- Answer as a Pandas Dataframe, sorted by population from highest to lowest. \n",
    "- The image in the cell below shows the first two lines of the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asia</td>\n",
       "      <td>3739902863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa</td>\n",
       "      <td>824954038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europe</td>\n",
       "      <td>792053486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North America</td>\n",
       "      <td>515041558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South America</td>\n",
       "      <td>375441666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Australia</td>\n",
       "      <td>32163025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       continent  population\n",
       "0           Asia  3739902863\n",
       "1         Africa   824954038\n",
       "2         Europe   792053486\n",
       "3  North America   515041558\n",
       "4  South America   375441666\n",
       "5      Australia    32163025"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q25 What is the population of each continent?\n",
    "import pandas as pd\n",
    "\n",
    "select = lambda x:pd.read_sql(x,conn)\n",
    "population_of_continent = select('''\n",
    "SELECT continent, SUM(population) AS 'population'\n",
    "FROM countries\n",
    "GROUP BY continent\n",
    "ORDER BY SUM(population) DESC\n",
    "''')\n",
    "population_of_continent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img population_of_continent.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"population_of_continent.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 26: *Plot the total population* of each continent.\n",
    "- Prepare a bar plot. \n",
    "- Put continents on the x-axis and total area on the y-axis. \n",
    "- The continents should be sorted along the x-axis alphabetically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# q26 Plot the total population of each continent? \n",
    "population_plot = population_of_continent.set_index('continent').sort_index()\n",
    "ax = population_plot.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 27: What is the *population density (population / area)* of all the *top 7* most dense *countries in Europe*?\n",
    "- Report these as a Pandas DataFrame sorted in decreasing order of population density. \n",
    "- The image below shows the first 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>16271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>6482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Malta</td>\n",
       "      <td>1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bermuda</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maldives</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bahrain</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      country  population density\n",
       "0      Monaco               16271\n",
       "1   Singapore                6482\n",
       "2       Malta                1266\n",
       "3     Bermuda                1241\n",
       "4    Maldives                1196\n",
       "5     Bahrain                1050\n",
       "6  Bangladesh                1023"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q27 What is the population density (population / area) of all the top 7 most \n",
    "# dense countries in Europe. \n",
    "density = select('''\n",
    "SELECT country, population/area AS 'population density'\n",
    "FROM countries\n",
    "ORDER BY population/area DESC\n",
    "LIMIT 7\n",
    "''')\n",
    "density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"population_density.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection to the database\n",
    "# Write your code here\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations, you are all done with work for CS220 course :) Mike and Meena wish you the best of luck for a bright future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
